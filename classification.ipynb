{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pjmz-RORV8E"
      },
      "source": [
        "# Apply labels with zero-shot classification\n",
        "\n",
        "This notebook shows how zero-shot classification can be used to perform text classification, labeling and topic modeling. txtai provides a light-weight wrapper around the zero-shot-classification pipeline in Hugging Face Transformers. This method works impressively well out of the box. Kudos to the Hugging Face team for the phenomenal work on zero-shot classification!\n",
        "\n",
        "The examples in this notebook pick the best matching label using a list of labels for a snippet of text.\n",
        "\n",
        "[tldrstory](https://github.com/neuml/tldrstory) has full-stack implementation of a zero-shot classification system using Streamlit, FastAPI and Hugging Face Transformers. There is also a [Medium article describing tldrstory](https://towardsdatascience.com/tldrstory-ai-powered-understanding-of-headlines-and-story-text-fc86abd702fc) and zero-shot classification. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk31rbYjSTYm"
      },
      "source": [
        "# Install dependencies\n",
        "\n",
        "Install `txtai` and all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pybind11 in c:\\users\\sebs1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.11.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XMQuuun2R06J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting txtaiNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Obtaining dependency information for txtai from https://files.pythonhosted.org/packages/bb/0b/d7dd51a844267d41afb3d0912da2af19c33b3145669b97676458b4a5bd46/txtai-6.2.0-py3-none-any.whl.metadata\n",
            "  Using cached txtai-6.2.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting faiss-cpu>=1.7.1.post2 (from txtai)\n",
            "  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "INFO: pip is looking at multiple versions of txtai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting txtai\n",
            "  Obtaining dependency information for txtai from https://files.pythonhosted.org/packages/f6/c5/5fd7419376e554a14c0c13a6d772ef1b494450707c797b7d34f5d98e27b0/txtai-6.1.0-py3-none-any.whl.metadata\n",
            "  Using cached txtai-6.1.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Obtaining dependency information for txtai from https://files.pythonhosted.org/packages/00/27/c1cd9dd00dcae9b3aac585ce5eb301aede135a8213c21dd05680eccd3d47/txtai-6.0.0-py3-none-any.whl.metadata\n",
            "  Using cached txtai-6.0.0-py3-none-any.whl.metadata (24 kB)\n",
            "  Using cached txtai-5.5.1-py3-none-any.whl (169 kB)\n",
            "Collecting numpy>=1.18.4 (from txtai)\n",
            "  Obtaining dependency information for numpy>=1.18.4 from https://files.pythonhosted.org/packages/28/75/3b679b41713bb60e2e8f6e2f87be72c971c9e718b1c17b8f8749240ddca8/numpy-1.26.2-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached numpy-1.26.2-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Collecting pyyaml>=5.3 (from txtai)\n",
            "  Obtaining dependency information for pyyaml>=5.3 from https://files.pythonhosted.org/packages/2b/9f/fbade56564ad486809c27b322d0f7e6a89c01f6b4fe208402e90d4443a99/PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting txtai\n",
            "  Using cached txtai-5.5.0-py3-none-any.whl (169 kB)\n",
            "  Using cached txtai-5.4.0-py3-none-any.whl (166 kB)\n",
            "  Using cached txtai-5.3.0-py3-none-any.whl (159 kB)\n",
            "  Using cached txtai-5.2.0-py3-none-any.whl (154 kB)\n",
            "INFO: pip is still looking at multiple versions of txtai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached txtai-5.1.0-py3-none-any.whl (147 kB)\n",
            "  Using cached txtai-5.0.0-py3-none-any.whl (147 kB)\n",
            "  Using cached txtai-4.6.0-py3-none-any.whl (135 kB)\n",
            "  Using cached txtai-4.5.0-py3-none-any.whl (134 kB)\n",
            "  Using cached txtai-4.4.0-py3-none-any.whl (134 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached txtai-4.3.1-py3-none-any.whl (127 kB)\n",
            "  Using cached txtai-4.3.0-py3-none-any.whl (127 kB)\n",
            "  Using cached txtai-4.2.1-py3-none-any.whl (124 kB)\n",
            "  Using cached txtai-4.2.0-py3-none-any.whl (124 kB)\n",
            "  Using cached txtai-4.1.0-py3-none-any.whl (122 kB)\n",
            "  Using cached txtai-4.0.0-py3-none-any.whl (118 kB)\n",
            "  Using cached txtai-3.7.0-py3-none-any.whl (87 kB)\n",
            "  Using cached txtai-3.6.0-py3-none-any.whl (80 kB)\n",
            "  Using cached txtai-3.5.0-py3-none-any.whl (77 kB)\n",
            "  Using cached txtai-3.4.0-py3-none-any.whl (76 kB)\n",
            "  Using cached txtai-3.3.0-py3-none-any.whl (75 kB)\n",
            "  Using cached txtai-3.2.0-py3-none-any.whl (68 kB)\n",
            "  Using cached txtai-3.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting aiohttp>=3.7.4 (from txtai)\n",
            "  Obtaining dependency information for aiohttp>=3.7.4 from https://files.pythonhosted.org/packages/4e/13/e929a6a50288e60ade3961b294d2f5aeb251b6579e4290a5397e484d0df9/aiohttp-3.9.1-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached aiohttp-3.9.1-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
            "Collecting annoy>=1.16.3 (from txtai)\n",
            "  Using cached annoy-1.17.3.tar.gz (647 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting apache-libcloud>=3.3.1 (from txtai)\n",
            "  Obtaining dependency information for apache-libcloud>=3.3.1 from https://files.pythonhosted.org/packages/45/fe/f450315f92d9f089fa25d8acbdd056bb780c83ffa0e275b519a04954bff1/apache_libcloud-3.8.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached apache_libcloud-3.8.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting fastapi>=0.61.1 (from txtai)\n",
            "  Obtaining dependency information for fastapi>=0.61.1 from https://files.pythonhosted.org/packages/ad/b9/b7ea33663daffa9db94119ea2a3df8f97bdca297024145fe79a5a13d37af/fastapi-0.105.0-py3-none-any.whl.metadata\n",
            "  Using cached fastapi-0.105.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting fasttext>=0.9.2 (from txtai)\n",
            "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [28 lines of output]\n",
            "      c:\\Users\\SebS1\\AppData\\Local\\Programs\\Python\\Python312\\python.exe: No module named pip\n",
            "      Traceback (most recent call last):\n",
            "        File \"<string>\", line 38, in __init__\n",
            "      ModuleNotFoundError: No module named 'pybind11'\n",
            "      \n",
            "      During handling of the above exception, another exception occurred:\n",
            "      \n",
            "      Traceback (most recent call last):\n",
            "        File \"c:\\Users\\SebS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
            "          main()\n",
            "        File \"c:\\Users\\SebS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
            "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"c:\\Users\\SebS1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
            "          return hook(config_settings)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\SebS1\\AppData\\Local\\Temp\\pip-build-env-knft2p4p\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
            "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        File \"C:\\Users\\SebS1\\AppData\\Local\\Temp\\pip-build-env-knft2p4p\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
            "          self.run_setup()\n",
            "        File \"C:\\Users\\SebS1\\AppData\\Local\\Temp\\pip-build-env-knft2p4p\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 480, in run_setup\n",
            "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
            "        File \"C:\\Users\\SebS1\\AppData\\Local\\Temp\\pip-build-env-knft2p4p\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
            "          exec(code, locals())\n",
            "        File \"<string>\", line 72, in <module>\n",
            "        File \"<string>\", line 41, in __init__\n",
            "      RuntimeError: pybind11 install failed.\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install txtai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package           Version\n",
            "----------------- -------\n",
            "asttokens         2.4.1\n",
            "colorama          0.4.6\n",
            "comm              0.2.0\n",
            "debugpy           1.8.0\n",
            "decorator         5.1.1\n",
            "executing         2.0.1\n",
            "ipykernel         6.27.1\n",
            "ipython           8.18.1\n",
            "jedi              0.19.1\n",
            "jupyter_client    8.6.0\n",
            "jupyter_core      5.5.1\n",
            "matplotlib-inline 0.1.6\n",
            "nest-asyncio      1.5.8\n",
            "packaging         23.2\n",
            "parso             0.8.3\n",
            "pip               23.2.1\n",
            "platformdirs      4.1.0\n",
            "prompt-toolkit    3.0.43\n",
            "psutil            5.9.7\n",
            "pure-eval         0.2.2\n",
            "pybind11          2.11.1\n",
            "Pygments          2.17.2\n",
            "python-dateutil   2.8.2\n",
            "pywin32           306\n",
            "pyzmq             25.1.2\n",
            "six               1.16.0\n",
            "stack-data        0.6.3\n",
            "tornado           6.4\n",
            "traitlets         5.14.0\n",
            "wcwidth           0.2.12\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNPJ95cdTKSS"
      },
      "source": [
        "# Create a Labels instance\n",
        "\n",
        "The Labels instance is the main entrypoint for zero-shot classification. This is a light-weight wrapper around the zero-shot-classification pipeline in Hugging Face Transformers.\n",
        "\n",
        "In addition to the default model, additional models can be found on the [Hugging Face model hub](https://huggingface.co/models?search=mnli).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nTDwXOUeTH2-"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'txtai'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtxtai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Labels\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create labels model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m Labels()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'txtai'"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "\n",
        "from txtai.pipeline import Labels\n",
        "\n",
        "# Create labels model\n",
        "labels = Labels()\n",
        "\n",
        "# Alternate models can be used via passing the model path as shown below\n",
        "# labels = Labels(\"roberta-large-mnli\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vGR_piwZZO6"
      },
      "source": [
        "# Applying labels to text\n",
        "\n",
        "The example below shows how a zero-shot classifier can be applied to arbitary text. The default model for the zero-shot classification pipeline is *bart-large-mnli*. \n",
        "\n",
        "Look at the results below. It's nothing short of amazing✨ how well it performs. These aren't all simple even for a human. For example, intercepted was purposely picked as that is more common in football than basketball. The amount of knowledge stored in larger Transformer models continues to impress me. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K2YJJzsVtfq",
        "outputId": "7a1edf58-15e0-46c8-958e-3a8e6045f802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text                                                                        Label\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Dodgers lose again, give up 3 HRs in a loss to the Giants                   Baseball\n",
            "Giants 5 Cardinals 4 final in extra innings                                 Baseball\n",
            "Dodgers drop Game 2 against the Giants, 5-4                                 Baseball\n",
            "Flyers 4 Lightning 1 final. 45 saves for the Lightning.                     Hockey\n",
            "Slashing, penalty, 2 minute power play coming up                            Hockey\n",
            "What a stick save!                                                          Hockey\n",
            "Leads the NFL in sacks with 9.5                                             Football\n",
            "UCF 38 Temple 13                                                            Football\n",
            "With the 30 yard completion, down to the 10 yard line                       Football\n",
            "Drains the 3pt shot!!, 0:15 remaining in the game                           Basketball\n",
            "Intercepted! Drives down the court and shoots for the win                   Basketball\n",
            "Massive dunk!!! they are now up by 15 with 2 minutes to go                  Basketball\n"
          ]
        }
      ],
      "source": [
        "data = [\"Dodgers lose again, give up 3 HRs in a loss to the Giants\",\n",
        "        \"Giants 5 Cardinals 4 final in extra innings\",\n",
        "        \"Dodgers drop Game 2 against the Giants, 5-4\",\n",
        "        \"Flyers 4 Lightning 1 final. 45 saves for the Lightning.\",\n",
        "        \"Slashing, penalty, 2 minute power play coming up\",\n",
        "        \"What a stick save!\",\n",
        "        \"Leads the NFL in sacks with 9.5\",\n",
        "        \"UCF 38 Temple 13\",\n",
        "        \"With the 30 yard completion, down to the 10 yard line\",\n",
        "        \"Drains the 3pt shot!!, 0:15 remaining in the game\",\n",
        "        \"Intercepted! Drives down the court and shoots for the win\",\n",
        "        \"Massive dunk!!! they are now up by 15 with 2 minutes to go\"]\n",
        "\n",
        "# List of labels\n",
        "tags = [\"happy\", \"sad\", \"angry\", \"anxious\", \"excited\", \"romantic\"]\n",
        "\n",
        "print(\"%-75s %s\" % (\"Text\", \"Label\"))\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for text in data:\n",
        "    print(\"%-75s %s\" % (text, tags[labels(text, tags)[0][0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tGAzCxsHLy"
      },
      "source": [
        "# Let's try emoji 😀\n",
        "\n",
        "Does the model have knowledge of emoji? Check out the run below, sure looks like it does! Notice the labels are applied based on the perspective from which the information is presented. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIf064M9pbjn",
        "outputId": "1d104014-e9ca-4c89-d259-2b5b231840ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text                                                                        Label\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Dodgers lose again, give up 3 HRs in a loss to the Giants                   😡\n",
            "Giants 5 Cardinals 4 final in extra innings                                 😀\n",
            "Dodgers drop Game 2 against the Giants, 5-4                                 😡\n",
            "Flyers 4 Lightning 1 final. 45 saves for the Lightning.                     😀\n",
            "Slashing, penalty, 2 minute power play coming up                            😡\n",
            "What a stick save!                                                          😀\n",
            "Leads the NFL in sacks with 9.5                                             😀\n",
            "UCF 38 Temple 13                                                            😀\n",
            "With the 30 yard completion, down to the 10 yard line                       😀\n",
            "Drains the 3pt shot!!, 0:15 remaining in the game                           😀\n",
            "Intercepted! Drives down the court and shoots for the win                   😀\n",
            "Massive dunk!!! they are now up by 15 with 2 minutes to go                  😀\n"
          ]
        }
      ],
      "source": [
        "tags = [\"😀\", \"😡\"]\n",
        "\n",
        "print(\"%-75s %s\" % (\"Text\", \"Label\"))\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for text in data:\n",
        "    print(\"%-75s %s\" % (text, tags[labels(text, tags)[0][0]]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
